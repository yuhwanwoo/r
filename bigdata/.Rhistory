content <- gsub("\t|&nbsp:","",content_filter_data)
#기존의 저장되어 있는 contentlist의 내용에 추가
contentlist <- c(contentlist,content_filter_data)
cat("\n",page)
}
final_data <- cbind(title,hit,url_val,contentlist)
final_data_list <- rbind(final_data_list,final_data)
cat("\n",i)
}
#mongodb에 저장하기 위해서는 크롤링해야한다.
con <- mongo(collection = "crawl","bigdata",url = "mongodb://127.0.0.1")
final_data_list=NULL
for(i in 0:9){
myurl <-paste0("https://www.clien.net/service/group/community?&od=T31&po=",i)
url_data <- readLines(myurl,encoding = "UTF-8")
####title추출####
final_filter_data <- url_data[str_detect(url_data,"subject_fixed")]
final_filter_data
title <- str_extract(final_filter_data,"(?<=\">).*(?=</span>)")
####hit추출
hit_data <- url_data[str_detect(url_data,"<span class=\"hit\">")]
hit_data
hit <- str_extract(hit_data,"(?<=\">).*(?=</span>)")[-1]
hit
####url추출
str_detect(url_data,"subject_fixed")
myurl <- url_data[which(str_detect(url_data,"subject_fixed"))-3]
url_val <- str_extract(myurl,"(?<=href=\").*(?=data-role)")
url_val <- str_sub(url_val,end = -3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
############url을 이용해서 content항목 추출
contentlist=NULL #최초 변수 선언시 null로 초기화
for(page in 1:length(url_val)){
contentdata <- readLines(url_val[page],encoding = "UTF-8")
start=which(str_detect(contentdata,"post_content"))
start
end=which(str_detect(contentdata,"post_ccls"))
end
content_filter_data <- contentdata[start:end]
content_filter_data <- paste(content_filter_data,collapse = "")
content_filter_data <- gsub("</*?>","",content_filter_data)
content_filter_data <- gsub("\t|&nbsp:","",content_filter_data)
#기존의 저장되어 있는 contentlist의 내용에 추가
contentlist <- c(contentlist,content_filter_data)
cat("\n",page)
}
final_data <- cbind(title,hit,url_val,contentlist)
final_data_list <- rbind(final_data_list,final_data)
cat("\n",i)
}
####csv파일로 생성####
write.csv(final_data_list,"crawl_data.csv")
save(final_data,file="crawl_data.RData")
#######mongodb에 저장하기
if(con$count()>0){
con$drop()
}
##mongodb에 데이터를 저장하기 위해서 dataframe으로 변환
final_mongodata <- data.frame(final_data_list)
####csv파일로 생성####
write.csv(final_data_list,"crawl_data.csv")
save(final_data,file="crawl_data.RData")
con$drop()
#######mongodb에 저장하기
if(con$count()>0){
con$drop()
}
##mongodb에 데이터를 저장하기 위해서 dataframe으로 변환
final_mongodata <- data.frame(final_data_list)
con$insert(final_mongodata)
install.packages("N2H4")
library(N2H4)
url <- "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=100&oid=020&aid=0003276790"
library(stringr)
getAllComment(url)
library(dplyr)
getAllComment(url) %>%
select(userName,contents) -> mydata
url <- "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=100&oid=020&aid=0003276790"
getAllComment(url) %>%
select(userName,contents) -> mydata
comments
mydata
#css의 선택자를 활용할 수 있는 방법 - rvest
install.packages("rvest")
install.packages("rvest")
library(rvest)
url <-paste0("https://www.clien.net/service/group/community?&od=T31&po=0")
readPage <- read_html(url)
readPage
readPage %>%
html_nodes("span.subject_fixed") ->title_data
title_data
readPage %>%
html_nodes("span.subject_fixed") %>%
html_text() -> title_data
title_data
readPage %>%
html_nodes("span.subject_fixed") %>%
html_text() -> title_data
title_data
readPage %>%
html_nodes("span.subject_fixed") %>%
html_text() -> title_data
install.packages("KONLP")
library(KoNLP)
install.packages("sejong")
library(KoNLP)
library("sejong")
library(KoNLP)
install.packages("sejong")
y
install.packages("Sejong")
library(KoNLP)
install.packages("hash")
library(KoNLP)
install.packages("tJava")
library(KoNLP)
install.packages("rJava")
library(KoNLP)
install.packages("tau")
install.packages("RSQLite")
install.packages("devtools")
library(KoNLP)
library(stringr)
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
class(sampledata)
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
sampledata <- comments[1:1000]
class(sampledata)
####################형태소 분석을 하기 위해서 명사 분리###########33
#댓글을 분리하면 분리된 명사의 개수가 다르므로 리스트를 이용
data_list=list()
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
data_list[[2]]
# /로 분할 - 리스트의 모든 요소에 저장된 문자열을 /로 분리
#                     => N이 있는 문자열의 첫번째 요소 가져오기
# sapply를 이용하면 반복작업을 할 수 있다.
sapply(data.frame(test=c(1,2,3,4,5,6),
test2=c(3,3,3,3,3,3)
), #반복작업할 데이터
function(x){
x[1]
} #반복해서 적용할 함수
)
# /로 분할 - 리스트의 모든 요소에 저장된 문자열을 /로 분리
#                     => N이 있는 문자열의 첫번째 요소 가져오기
# sapply를 이용하면 반복작업을 할 수 있다.
sapply(data.frame(test=c(1,2,3,4,5,6),
test2=c(3,4,5,6,7,8)
), #반복작업할 데이터
function(x){
x[1]
} #반복해서 적용할 함수
)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
})
head(wordlist,10)
install.packages("KONLP")
install.packages("Sejong")
install.packages("hash")
install.packages("rJava")
library(KoNLP)
library(KoNLP)
library(stringr)
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
convertHangulStringToJamos("R는 많은 공헌자에의한 공동 프로젝트입니다")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
class(sampledata)
####################형태소 분석을 하기 위해서 명사 분리###########33
#댓글을 분리하면 분리된 명사의 개수가 다르므로 리스트를 이용
data_list=list()
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
head(data_list,20)
# /로 분할 - 리스트의 모든 요소에 저장된 문자열을 /로 분리
#                     => N이 있는 문자열의 첫번째 요소 가져오기
# sapply를 이용하면 반복작업을 할 수 있다.
sapply(data.frame(test=c(1,2,3,4,5,6),
test2=c(3,4,5,6,7,8)
), #반복작업할 데이터
function(x){
x[1]
} #반복해서 적용할 함수
)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
class(wordlist)                                          })
head(wordlist,10)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
class(wordlist)                                          })
class(data_list)
library(KoNLP)
library(stringr)
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
convertHangulStringToJamos("R는 많은 공헌자에의한 공동 프로젝트입니다")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
class(sampledata)
####################형태소 분석을 하기 위해서 명사 분리###########33
#댓글을 분리하면 분리된 명사의 개수가 다르므로 리스트를 이용
data_list=list()
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
head(data_list,20)
# /로 분할 - 리스트의 모든 요소에 저장된 문자열을 /로 분리
#                     => N이 있는 문자열의 첫번째 요소 가져오기
# sapply를 이용하면 반복작업을 할 수 있다.
sapply(data.frame(test=c(1,2,3,4,5,6),
test2=c(3,4,5,6,7,8)
), #반복작업할 데이터
function(x){
x[1]
} #반복해서 적용할 함수
)
class(data_list)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
class(wordlist)                                          })
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
})
head(wordlist,10)
head(data_list,20)
class(data_list)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,10)
head(data_list,20)
head(data_list,10)
head(data_list,20)
library(KoNLP)
library(stringr)
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
convertHangulStringToJamos("R는 많은 공헌자에의한 공동 프로젝트입니다")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
class(sampledata)
####################형태소 분석을 하기 위해서 명사 분리###########33
#댓글을 분리하면 분리된 명사의 개수가 다르므로 리스트를 이용
data_list=list()
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
head(data_list,20)
class(data_list)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,10)
head(wordlist,20)
#리스트를 unlist로 변환
class(unlist(data_list))
wordlist <- sapply(str_split(unlist(data_list),"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,20)
tablewordlist <- table(wordlist)
#table함수를 이용해서 단어의 빈도수를 구하기
tablewordlist <- table(wordlist)
table
tablewordlist[i]
tablewordlist
tablewordlist[89]
tablewordlist[89]
names(tablewordlist)
#분석한 데이터를 이용해서 sort
sort(tablewordlist,decreasing = T)[1:100]
#분석결과를 가지고 기준을 정해서 정리 - 한 글자를 빼고
nchar("글자수")
names(tablewordlist)
tablewordlist_result <- tablewordlist[nchar(names(tablewordlist))>1]
tablewordlist_result <- sort(tablewordlist,decreasing = T)[1:100]
tablewordlist_result
tablewordlist_result <- tablewordlist[nchar(names(tablewordlist))>1]
tablewordlist_result <- sort(tablewordlist_result,decreasing = T)[1:100]
tablewordlist_result
install.packages("wordcloud")
install.packages("RcolorBrewer")
install.packages("RColorBrewer")
library(wordcloud)
library(RColorBrewer)
library(wordcloud)
#RColorBrewer
#모든 색상 파레트를 보여준다다
display.brewer.all(n=10,exact.n = F)
#RColorBrewer
#모든 색상 파레트를 보여준다다
display.brewer.all(n=10,exact.n = F)
brewer.pal.info
display.brewer.all(type = "div")
display.brewer.all(type = "qual")
display.brewer.all(type = "seq")
names(tablewordlist)
#table함수를 이용해서 단어의 빈도수를 구하기
#table함수는 벡터에 저장되어 있는 모든 단어들의 빈도수를 계산해서 변환 - 단어를 이용해서 변수명으로 사용
tablewordlist <- table(wordlist)
tablewordlist
names(tablewordlist)
#분석한 결과가 저장되어 있는 tablewordlist_result의
#값을 단어와 숫자를 각각 저장
word <- names(tablewordlist_result)
count <- as.numeric(tablewordlist_result)
brewer.pal.info
mycolor <- brewer.pal(n=12,name="Paired")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
mycolor <- brewer.pal(n=12,name="Paired")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("KONLP")
install.packages("Sejong")
install.packages("hash")
install.packages("rJava")
install.packages("tau")
install.packages("RSQLite")
install.packages("devtools")
library(KoNLP)
library(stringr)
library(wordcloud)
library(RColorBrewer)
####NoNLP의 함수를 테스트####
extractNoun("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
convertHangulStringToJamos("R는 많은 공헌자에의한 공동 프로젝트입니다")
##################분석할 샘플데이터 로딩
load("comments.RData")
load("score.RData")
length(comments)
length(score)
head(comments,10)
head(score,10)
sampledata <- comments[1:1000]
class(sampledata)
####################형태소 분석을 하기 위해서 명사 분리###########33
#댓글을 분리하면 분리된 명사의 개수가 다르므로 리스트를 이용
data_list=list()
for(i in 1:length(sampledata)){
data <- SimplePos09(sample(sampledata[i]))
data_list[[i]] <- data
}
head(data_list,20)
# /로 분할 - 리스트의 모든 요소에 저장된 문자열을 /로 분리
#                     => N이 있는 문자열의 첫번째 요소 가져오기
# sapply를 이용하면 반복작업을 할 수 있다.
# sapply(data.frame(test=c(1,2,3,4,5,6),
#                   test2=c(3,4,5,6,7,8)
#                   ), #반복작업할 데이터
#        function(x){
#         x[1]
#          } #반복해서 적용할 함수
#        )
class(data_list)
#리스트를 unlist로 변환
class(unlist(data_list))
wordlist <- sapply(str_split(unlist(data_list),"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,20)
head(data_list,20)
#table함수를 이용해서 단어의 빈도수를 구하기
#table함수는 벡터에 저장되어 있는 모든 단어들의 빈도수를 계산해서 변환 - 단어를 이용해서 변수명으로 사용
tablewordlist <- table(wordlist)
tablewordlist[i]
tablewordlist
tablewordlist[89]
names(tablewordlist)
#분석한 데이터를 이용해서 sort
sort(tablewordlist,decreasing = T)[1:100]
#분석결과를 가지고 기준을 정해서 정리 - 한 글자를 빼고
nchar("글자수")
tablewordlist_result <- tablewordlist[nchar(names(tablewordlist))>1]
tablewordlist_result <- sort(tablewordlist_result,decreasing = T)[1:100]
tablewordlist_result
#RColorBrewer
#모든 색상 파레트를 보여준다다
display.brewer.all(n=10,exact.n = F)
brewer.pal.info
display.brewer.all(type = "div")
display.brewer.all(type = "qual")
display.brewer.all(type = "seq")
#분석한 결과가 저장되어 있는 tablewordlist_result의
#값을 단어와 숫자를 각각 저장
word <- names(tablewordlist_result)
count <- as.numeric(tablewordlist_result)
mycolor <- brewer.pal(n=12,name="Paired")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
class(data_list)
#리스트를 unlist로 변환
class(data_list)
wordlist <- sapply(str_split(data_list,"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,20)
class(data_list)
#리스트를 unlist로 변환
class(unlist(data_list))
wordlist <- sapply(str_split(unlist(data_list),"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,20)
data_list
head(data_list,20)
#리스트를 unlist로 변환
class(unlist(data_list))
wordlist <- sapply(str_split(unlist(data_list),"/"),function(x){
x[1]
})
class(wordlist)
head(wordlist,20)
head(data_list,20)
#table함수를 이용해서 단어의 빈도수를 구하기
#table함수는 벡터에 저장되어 있는 모든 단어들의 빈도수를 계산해서 변환 - 단어를 이용해서 변수명으로 사용
tablewordlist <- table(wordlist)
tablewordlist[i]
tablewordlist
tablewordlist[89]
names(tablewordlist)
#분석한 데이터를 이용해서 sort
sort(tablewordlist,decreasing = T)[1:100]
#분석결과를 가지고 기준을 정해서 정리 - 한 글자를 빼고
nchar("글자수")
tablewordlist_result <- tablewordlist[nchar(names(tablewordlist))>1]
tablewordlist_result <- sort(tablewordlist_result,decreasing = T)[1:100]
tablewordlist_result
#RColorBrewer
#모든 색상 파레트를 보여준다다
display.brewer.all(n=10,exact.n = F)
brewer.pal.info
display.brewer.all(type = "div")
display.brewer.all(type = "qual")
display.brewer.all(type = "seq")
#분석한 결과가 저장되어 있는 tablewordlist_result의
#값을 단어와 숫자를 각각 저장
word <- names(tablewordlist_result)
count <- as.numeric(tablewordlist_result)
mycolor <- brewer.pal(n=12,name="Paired")
mycolor <- brewer.pal(n=12,name="Paired")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
brewer.pal.info
mycolor <- brewer.pal(n=11,name="RdGy")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
mycolor <- brewer.pal(n=9,name="RdGy")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
mycolor <- brewer.pal(n=9,name="Accent")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
mycolor <- brewer.pal(n=12,name="Paired")
wordcloud(words=word,freq = count,random.order = F,colors = mycolor,scale = c(7,0.3))
